{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-09T14:41:26.300603Z",
     "iopub.status.busy": "2025-04-09T14:41:26.300401Z",
     "iopub.status.idle": "2025-04-09T14:41:56.664675Z",
     "shell.execute_reply": "2025-04-09T14:41:56.663829Z",
     "shell.execute_reply.started": "2025-04-09T14:41:26.300583Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.47.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers==4.47.0) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers==4.47.0) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers==4.47.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers==4.47.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers==4.47.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers==4.47.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers==4.47.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers==4.47.0) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers==4.47.0) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers==4.47.0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.0) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.0) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>=4.27->transformers==4.47.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers==4.47.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers==4.47.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers==4.47.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers==4.47.0) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\amart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.4.3)\n",
      "Requirement already satisfied: rouge-score in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.1.2)\n",
      "Requirement already satisfied: bert-score in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.3.13)\n",
      "Requirement already satisfied: sacrebleu in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torch in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.2.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from evaluate) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from evaluate) (0.28.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rouge-score) (2.2.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: transformers>=3.0.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from bert-score) (4.47.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from bert-score) (3.10.0)\n",
      "Requirement already satisfied: portalocker in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sacrebleu) (3.1.1)\n",
      "Requirement already satisfied: regex in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sacrebleu) (5.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from datasets>=2.0.0->evaluate) (3.11.13)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers>=3.0.0->bert-score) (0.5.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->bert-score) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->bert-score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->bert-score) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->bert-score) (3.2.1)\n",
      "Requirement already satisfied: click in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk->rouge-score) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from portalocker->sacrebleu) (308)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\amart\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\amart\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "C:\\Users\\amart\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers==4.47.0\n",
    "%pip install evaluate rouge-score bert-score sacrebleu torch sentencepiece\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    BartModel,\n",
    "    BartForConditionalGeneration,\n",
    "    BartTokenizer,\n",
    "    ViTModel,\n",
    "    ViTImageProcessor\n",
    ")\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score_compute\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:41:56.666575Z",
     "iopub.status.busy": "2025-04-09T14:41:56.665550Z",
     "iopub.status.idle": "2025-04-09T14:41:56.674105Z",
     "shell.execute_reply": "2025-04-09T14:41:56.673167Z",
     "shell.execute_reply.started": "2025-04-09T14:41:56.666552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MuSEDataset(Dataset):\n",
    "    def __init__(self, tsv_path, objects_pkl_path, descriptions_pkl_path, image_dir):\n",
    "        super().__init__()\n",
    "        self.df = pd.read_csv(tsv_path, sep='\\t')\n",
    "        self.df['pid'] = self.df['pid'].astype(str)\n",
    "\n",
    "        with open(objects_pkl_path, 'rb') as f:\n",
    "            self.objects_data = pickle.load(f)\n",
    "\n",
    "        with open(descriptions_pkl_path, 'rb') as f:\n",
    "            self.descriptions_data = pickle.load(f)\n",
    "\n",
    "        self.image_dir = image_dir\n",
    "        self.pids = self.df['pid'].tolist()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.pids[idx]\n",
    "\n",
    "        row = self.df[self.df.pid == pid].iloc[0]\n",
    "        caption = str(row['text']).replace('\\'', '')\n",
    "        target = str(row['target_of_sarcasm'])\n",
    "        explanation = str(row['explanation'])\n",
    "\n",
    "        description = self.descriptions_data.get(pid, \"\")\n",
    "        \n",
    "        objects_info = self.objects_data.get(pid, {'classes': []}) # Handle missing PIDs\n",
    "        object_list = objects_info.get('classes', [])\n",
    "\n",
    "        image_path = os.path.join(self.image_dir, f\"{pid}.jpg\")\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Image not found for PID {pid} at {image_path}. Returning None.\")\n",
    "            return None\n",
    "\n",
    "        return {\n",
    "            \"pid\": pid,\n",
    "            \"image\": image,\n",
    "            \"caption\": caption,\n",
    "            \"description\": description,\n",
    "            \"objects\": object_list,\n",
    "            \"target\": target,\n",
    "            \"explanation\": explanation\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:41:56.675538Z",
     "iopub.status.busy": "2025-04-09T14:41:56.675159Z",
     "iopub.status.idle": "2025-04-09T14:41:56.770299Z",
     "shell.execute_reply": "2025-04-09T14:41:56.768968Z",
     "shell.execute_reply.started": "2025-04-09T14:41:56.675505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MuseDataCollator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        bart_tokenizer: BartTokenizer,\n",
    "        vit_processor: ViTImageProcessor,\n",
    "        vit_model: nn.Module,\n",
    "        text_max_len: int = 256,\n",
    "        explanation_max_len: int = 64\n",
    "    ):\n",
    "        self.bart_tokenizer = bart_tokenizer\n",
    "        self.vit_processor = vit_processor\n",
    "        self.vit_model = vit_model\n",
    "        self.text_max_len = text_max_len\n",
    "        self.explanation_max_len = explanation_max_len\n",
    "        self.bart_sep_token = self.bart_tokenizer.eos_token\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        batch = [item for item in batch if item is not None]\n",
    "        if not batch:\n",
    "            return None\n",
    "\n",
    "        images = [item['image'] for item in batch]\n",
    "        captions = [item['caption'] for item in batch]\n",
    "        descriptions = [item['description'] for item in batch]\n",
    "        objects_list = [item['objects'] for item in batch]\n",
    "        targets = [item['target'] for item in batch]\n",
    "        explanations = [item['explanation'] for item in batch]\n",
    "        \n",
    "        image_inputs = self.vit_processor(images=images, return_tensors=\"pt\").to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "             vit_outputs = self.vit_model(**image_inputs)\n",
    "             E_v_batch = vit_outputs.last_hidden_state\n",
    "\n",
    "        T_concat_batch_strings = []\n",
    "        for c, d, o_list, t in zip(captions, descriptions, objects_list, targets):\n",
    "            o_string = \" \".join(o_list)\n",
    "            t_knowledge = ' '.join((c, d, o_string))\n",
    "            t_concat = ' '.join((t_knowledge, self.bart_sep_token, t))\n",
    "            T_concat_batch_strings.append(t_concat)\n",
    "\n",
    "        tokenized_T_concat = self.bart_tokenizer(\n",
    "            T_concat_batch_strings,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.text_max_len\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        tokenized_explanations = self.bart_tokenizer(\n",
    "            explanations,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.explanation_max_len\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        labels = tokenized_explanations['input_ids']\n",
    "\n",
    "        return {\n",
    "            'E_v': E_v_batch,\n",
    "            'T_concat_ids': tokenized_T_concat['input_ids'],\n",
    "            'attention_mask': tokenized_T_concat['attention_mask'],\n",
    "            'target_explanation_ids': labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-09T14:41:56.771880Z",
     "iopub.status.busy": "2025-04-09T14:41:56.771525Z",
     "iopub.status.idle": "2025-04-09T14:41:56.801996Z",
     "shell.execute_reply": "2025-04-09T14:41:56.801192Z",
     "shell.execute_reply.started": "2025-04-09T14:41:56.771853Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtractorViT(nn.Module):\n",
    "    def __init__(self, vit_model_name=\"google/vit-base-patch16-224-in21k\"):\n",
    "        super().__init__()\n",
    "        self.vit_processor = ViTImageProcessor.from_pretrained(vit_model_name)\n",
    "        self.vit_model = ViTModel.from_pretrained(vit_model_name)\n",
    "        self.embedding_dim = self.vit_model.config.hidden_size\n",
    "\n",
    "    def forward(self, image):\n",
    "        try:\n",
    "            processed_inputs = self.vit_processor(images=image, return_tensors=\"pt\")\n",
    "            processed_inputs = processed_inputs.to(self.vit_model.device)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image with ViTProcessor: {e}\")\n",
    "            return None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.vit_model(**processed_inputs)\n",
    "\n",
    "        E_v = outputs.last_hidden_state\n",
    "        return E_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:41:56.804123Z",
     "iopub.status.busy": "2025-04-09T14:41:56.803828Z",
     "iopub.status.idle": "2025-04-09T14:41:59.117076Z",
     "shell.execute_reply": "2025-04-09T14:41:59.116132Z",
     "shell.execute_reply.started": "2025-04-09T14:41:56.804102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BART_SF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bart_model_name,\n",
    "        bart_tokenizer,\n",
    "        vit_feature_extractor=FeatureExtractorViT(),\n",
    "        vit_seq_len=197,\n",
    "        text_seq_len=256\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bart_tokenizer = bart_tokenizer\n",
    "        self.bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name)\n",
    "        self.text_embedding_dim = self.bart_model.config.d_model\n",
    "\n",
    "        self.vit_feature_extractor = vit_feature_extractor\n",
    "        self.image_embedding_dim = self.vit_feature_extractor.embedding_dim\n",
    "\n",
    "        if self.text_embedding_dim != self.image_embedding_dim:\n",
    "            self.image_feature_proj_dim = nn.Linear(self.image_embedding_dim, self.text_embedding_dim)\n",
    "            self.D_f = self.text_embedding_dim\n",
    "        else:\n",
    "            self.image_feature_proj_dim = nn.Identity()\n",
    "            self.D_f = self.text_embedding_dim\n",
    "            \n",
    "        self.vit_seq_len = vit_seq_len\n",
    "        self.text_seq_len = text_seq_len\n",
    "        if self.vit_seq_len != self.text_seq_len:\n",
    "            self.image_seq_proj_len = nn.Linear(self.vit_seq_len, self.text_seq_len)\n",
    "        else:\n",
    "            print(\"ViT and Text sequence lengths match. No sequence projection layer needed.\")\n",
    "            self.image_seq_proj_len = None\n",
    "\n",
    "        self.query_v = nn.Linear(self.D_f, self.D_f)\n",
    "        self.key_v = nn.Linear(self.D_f, self.D_f)\n",
    "        self.value_v = nn.Linear(self.D_f, self.D_f)\n",
    "        \n",
    "        self.query_t = nn.Linear(self.D_f, self.D_f)\n",
    "        self.key_t = nn.Linear(self.D_f, self.D_f)\n",
    "        self.value_t = nn.Linear(self.D_f, self.D_f)\n",
    "        \n",
    "        self.gate_v_layer = nn.Linear(self.D_f, self.D_f)\n",
    "        self.gate_t_layer = nn.Linear(self.D_f, self.D_f)\n",
    "        \n",
    "        self.alpha1 = nn.Parameter(torch.tensor(1.0))\n",
    "        self.alpha2 = nn.Parameter(torch.tensor(1.0))\n",
    "        self.beta1 = nn.Parameter(torch.tensor(1.0))\n",
    "        self.beta2 = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "    def _attention(self, Q, K, V, d_f):\n",
    "        A = torch.matmul(Q, K.transpose(-1, -2))\n",
    "        A = torch.softmax(A / math.sqrt(d_f), dim=-1)\n",
    "        A = torch.matmul(A, V)\n",
    "        return A\n",
    "        \n",
    "    def forward(self, E_v, T_concat_text, attention_mask, target_explanation_ids=None, generate=False):\n",
    "        E_v = self.image_feature_proj_dim(E_v)\n",
    "\n",
    "        encoder_outputs = self.bart_model.model.encoder(\n",
    "            input_ids=T_concat_text,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        E_t = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        if E_v.shape[1] != E_t.shape[1]:\n",
    "            if self.image_seq_proj_len is not None:\n",
    "                E_v_proj = self.image_seq_proj_len(E_v.transpose(1, 2))\n",
    "                E_v = E_v_proj.transpose(1, 2)\n",
    "            else:\n",
    "                print(f\"Error: Sequence length mismatch ({E_v.shape[1]} vs {E_t.shape[1]}) but no projection layer defined.\")\n",
    "                raise ValueError(\"Sequence lengths differ but no projection layer available.\")\n",
    "\n",
    "        Q_v, K_v, V_v = self.query_v(E_v), self.key_v(E_v), self.value_v(E_v)\n",
    "        A_v = self._attention(Q_v, K_v, V_v, self.D_f)\n",
    "        \n",
    "        Q_t, K_t, V_t = self.query_t(E_t), self.key_t(E_t), self.value_t(E_t)\n",
    "        A_t = self._attention(Q_t, K_t, V_t, self.D_f)\n",
    "\n",
    "        F_vt = A_t * E_v\n",
    "        F_tv = A_v * E_t\n",
    "\n",
    "        G_v = torch.sigmoid(self.gate_v_layer(E_v))\n",
    "        G_t = torch.sigmoid(self.gate_t_layer(E_t))\n",
    "\n",
    "        F1 = (G_v * F_tv) + ((1 - G_v) * F_vt)\n",
    "        F2 = (G_t * F_tv) + ((1 - G_t) * F_vt)\n",
    "        F_v = (G_v * E_v) + ((1 - G_v) * F_tv)\n",
    "        F_t = (G_t * E_t) + ((1 - G_t) * F_vt)\n",
    "\n",
    "        F_SF = self.alpha1 * F1 + self.alpha2 * F2 + self.beta1 * F_v + self.beta2 * F_t\n",
    "\n",
    "        if generate:\n",
    "            encoder_output_object = BaseModelOutputWithPastAndCrossAttentions(\n",
    "                last_hidden_state=F_SF\n",
    "            )\n",
    "            generated_ids = self.bart_model.generate(\n",
    "                 encoder_outputs=encoder_output_object,\n",
    "                 attention_mask=attention_mask,\n",
    "                 num_beams=4,\n",
    "                 early_stopping=True\n",
    "            )\n",
    "            return generated_ids\n",
    "        else:\n",
    "            labels = None\n",
    "            if target_explanation_ids is not None:\n",
    "                 labels = target_explanation_ids.clone()\n",
    "                 labels[labels == self.bart_tokenizer.pad_token_id] = -100\n",
    "\n",
    "            outputs = self.bart_model(\n",
    "                 encoder_outputs=(F_SF,),\n",
    "                 attention_mask=attention_mask,\n",
    "                 labels=labels,\n",
    "                 return_dict=True\n",
    "            )\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:41:59.118770Z",
     "iopub.status.busy": "2025-04-09T14:41:59.118303Z",
     "iopub.status.idle": "2025-04-09T14:41:59.124510Z",
     "shell.execute_reply": "2025-04-09T14:41:59.123746Z",
     "shell.execute_reply.started": "2025-04-09T14:41:59.118737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: BART_SF,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    optimizer: optim.Optimizer\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training Epoch\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        E_v_batch = batch['E_v'].to(DEVICE)\n",
    "        T_concat_ids_batch = batch['T_concat_ids'].to(DEVICE)\n",
    "        attention_mask_batch = batch['attention_mask'].to(DEVICE)\n",
    "        target_ids_batch = batch['target_explanation_ids'].to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            E_v=E_v_batch,\n",
    "            T_concat_text=T_concat_ids_batch,\n",
    "            attention_mask=attention_mask_batch,\n",
    "            target_explanation_ids=target_ids_batch,\n",
    "            generate=False\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    print(f\"Average Training Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:41:59.125719Z",
     "iopub.status.busy": "2025-04-09T14:41:59.125460Z",
     "iopub.status.idle": "2025-04-09T14:41:59.147569Z",
     "shell.execute_reply": "2025-04-09T14:41:59.146817Z",
     "shell.execute_reply.started": "2025-04-09T14:41:59.125699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: nn.Module, # Or specific class BART_SF\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    tokenizer: BartTokenizer, # Use specific tokenizer class if known\n",
    "    max_gen_length: int = 64,\n",
    "    num_samples_to_print: int = 5 # Set > 0 to print samples\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluates the model using ROUGE(1,2,L), BLEU(1-4 via Sacre), METEOR, BERTScore,\n",
    "    and prints sample reference/generated pairs.\n",
    "\n",
    "    Args:\n",
    "        model: The model instance (e.g., BART_SF).\n",
    "        data_loader: DataLoader for the evaluation set.\n",
    "        DEVICE: The DEVICE to run evaluation on ('cuda' or 'cpu').\n",
    "        tokenizer: The tokenizer used for decoding.\n",
    "        max_gen_length: Max length for generated sequences (Note: passed to generate if needed).\n",
    "        num_samples_to_print: How many reference/generated pairs to print.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated metric scores.\n",
    "              Returns None if evaluation fails.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_generated_texts = []\n",
    "    all_reference_texts = []\n",
    "    samples_printed_count = 0 # Counter for printed samples\n",
    "    metrics_loaded = True\n",
    "\n",
    "    # --- Initialize Metrics ---\n",
    "    try:\n",
    "        rouge_metric = evaluate.load('rouge')\n",
    "        # Using 'sacrebleu' for potentially easier access to BLEU-1..4 scores\n",
    "        bleu_metric = evaluate.load('sacrebleu')\n",
    "        meteor_metric = evaluate.load('meteor') # Requires NLTK + data\n",
    "        bertscore_metric = evaluate.load('bertscore')\n",
    "        print(\"Metrics (ROUGE, BLEU(Sacre), METEOR, BERTScore) loaded via evaluate.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading one or more metrics via evaluate: {e}\")\n",
    "        print(\"Ensure 'evaluate', 'rouge-score', 'sacrebleu', 'nltk', 'bert-score' are installed and NLTK data is available.\")\n",
    "        metrics_loaded = False\n",
    "        return None\n",
    "\n",
    "    # --- Check DataLoader Length ---\n",
    "    try:\n",
    "        dataloader_len = len(data_loader)\n",
    "        if dataloader_len == 0:\n",
    "             print(\"Error: Evaluation DataLoader is empty. Skipping evaluation.\")\n",
    "             return None\n",
    "        print(f\"Evaluation DataLoader contains {dataloader_len} batches.\")\n",
    "    except TypeError:\n",
    "         print(\"Warning: Could not determine DataLoader length beforehand.\")\n",
    "         dataloader_len = \"Unknown\"\n",
    "\n",
    "    print(\"Starting evaluation loop...\")\n",
    "    progress_bar = tqdm(data_loader, desc=\"Evaluating\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(progress_bar):\n",
    "            if batch is None: continue\n",
    "            try:\n",
    "                # Unpack batch and move to DEVICE\n",
    "                E_v_batch = batch['E_v'].to(DEVICE)\n",
    "                T_concat_ids_batch = batch['T_concat_ids'].to(DEVICE)\n",
    "                attention_mask_batch = batch['attention_mask'].to(DEVICE)\n",
    "                target_ids_batch = batch['target_explanation_ids'].to(DEVICE)\n",
    "\n",
    "                # Generate\n",
    "                generated_ids = model(E_v=E_v_batch, T_concat_text=T_concat_ids_batch,\n",
    "                                      attention_mask=attention_mask_batch, generate=True)\n",
    "\n",
    "                # Decode\n",
    "                generated_batch_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "                ref_ids_clone = target_ids_batch.clone()\n",
    "                ref_ids_clone[ref_ids_clone == -100] = tokenizer.pad_token_id\n",
    "                reference_batch_texts = tokenizer.batch_decode(ref_ids_clone, skip_special_tokens=True)\n",
    "\n",
    "                # --- Print Sample Outputs --- ## <<< ADDED BACK ##\n",
    "                if samples_printed_count < num_samples_to_print:\n",
    "                    num_to_print_this_batch = min(num_samples_to_print - samples_printed_count, len(generated_batch_texts))\n",
    "                    if num_to_print_this_batch > 0:\n",
    "                        print(f\"\\n--- Sample Outputs (Batch {i+1}) ---\")\n",
    "                        for idx in range(num_to_print_this_batch):\n",
    "                            print(f\"\\n[Sample {samples_printed_count + 1}]\")\n",
    "                            print(f\"  Reference : {reference_batch_texts[idx]}\")\n",
    "                            print(f\"  Generated : {generated_batch_texts[idx]}\")\n",
    "                            samples_printed_count += 1\n",
    "                        if num_to_print_this_batch > 0:\n",
    "                             print(\"-\" * 30)\n",
    "                # --- End Sample Printing --- ## <<< ADDED BACK ##\n",
    "\n",
    "                # --- Accumulate data for metrics ---\n",
    "                # Wrap references for sacrebleu: [[ref1], [ref2], ...]\n",
    "                references_for_bleu = [[ref] for ref in reference_batch_texts]\n",
    "\n",
    "                # Check for empty strings before adding, some metrics fail on them\n",
    "                valid_preds = [p for p, r in zip(generated_batch_texts, reference_batch_texts) if p and r]\n",
    "                valid_refs = [r for p, r in zip(generated_batch_texts, reference_batch_texts) if p and r]\n",
    "                valid_refs_for_bleu = [[r] for p, r in zip(generated_batch_texts, reference_batch_texts) if p and r]\n",
    "\n",
    "                if valid_preds: # Only add if there are valid pairs in the batch\n",
    "                    rouge_metric.add_batch(predictions=valid_preds, references=valid_refs)\n",
    "                    bleu_metric.add_batch(predictions=valid_preds, references=valid_refs_for_bleu)\n",
    "                    meteor_metric.add_batch(predictions=valid_preds, references=valid_refs)\n",
    "\n",
    "                    # Collect all for BERTScore (it might handle empties, but best to be consistent)\n",
    "                    all_generated_texts.extend(valid_preds)\n",
    "                    all_reference_texts.extend(valid_refs)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch {i+1}: {e}. Skipping.\")\n",
    "                # import traceback # Uncomment for debug\n",
    "                # traceback.print_exc()\n",
    "                continue\n",
    "\n",
    "    # --- Final Metric Computations ---\n",
    "    print(\"\\nCalculating final metrics...\")\n",
    "    if not all_generated_texts: # Check if any valid data was processed\n",
    "        print(\"Error: No valid texts were generated/collected. Cannot compute metrics.\")\n",
    "        return None\n",
    "\n",
    "    results = {}\n",
    "    computed_metrics = {}\n",
    "    try:\n",
    "        print(\"Computing ROUGE...\")\n",
    "        computed_metrics['rouge'] = rouge_metric.compute()\n",
    "        print(\"Computing BLEU (Sacre)...\")\n",
    "        computed_metrics['bleu'] = bleu_metric.compute()\n",
    "        print(\"Computing METEOR...\")\n",
    "        # !! This might fail again if NLTK/WordNet issue persists !!\n",
    "        computed_metrics['meteor'] = meteor_metric.compute()\n",
    "        print(\"Computing BERTScore...\")\n",
    "        computed_metrics['bertscore'] = bertscore_metric.compute(\n",
    "            predictions=all_generated_texts, references=all_reference_texts, lang=\"en\",\n",
    "            # model_type=\"microsoft/deberta-xlarge-mnli\" # Specify if needed\n",
    "            device=str(DEVICE)\n",
    "        )\n",
    "\n",
    "        # --- Format Results ---\n",
    "        # ROUGE\n",
    "        results['rouge1'] = computed_metrics['rouge'].get('rouge1', 0.0) # Use .get for safety\n",
    "        results['rouge2'] = computed_metrics['rouge'].get('rouge2', 0.0)\n",
    "        results['rougeL'] = computed_metrics['rouge'].get('rougeL', 0.0)\n",
    "\n",
    "        # BLEU (from Sacrebleu output)\n",
    "        results['bleu'] = computed_metrics['bleu'].get('score', 0.0) / 100.0\n",
    "        precisions = computed_metrics['bleu'].get('precisions', [0.0] * 4)\n",
    "        for i, prec in enumerate(precisions[:4]): # Ensure we only take up to 4\n",
    "             results[f'bleu-{i+1}'] = prec / 100.0\n",
    "\n",
    "        # METEOR\n",
    "        results['meteor'] = computed_metrics['meteor'].get('meteor', 0.0)\n",
    "\n",
    "        # BERTScore\n",
    "        results['bertscore_precision'] = np.mean(computed_metrics['bertscore'].get('precision', [0.0]))\n",
    "        results['bertscore_recall'] = np.mean(computed_metrics['bertscore'].get('recall', [0.0]))\n",
    "        results['bertscore_f1'] = np.mean(computed_metrics['bertscore'].get('f1', [0.0]))\n",
    "\n",
    "\n",
    "        print(\"\\nEvaluation Metrics Calculated:\")\n",
    "        # (Metric printing logic remains the same)\n",
    "        # ...\n",
    "        return results\n",
    "\n",
    "    except ImportError as e:\n",
    "         print(f\"\\nERROR calculating metrics: {e}\")\n",
    "         print(\"This often indicates a missing dependency (like NLTK data for METEOR).\")\n",
    "         return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError calculating final metrics: {e}\")\n",
    "        # import traceback\n",
    "        # traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T14:41:59.148621Z",
     "iopub.status.busy": "2025-04-09T14:41:59.148378Z",
     "iopub.status.idle": "2025-04-09T15:09:36.620973Z",
     "shell.execute_reply": "2025-04-09T15:09:36.620074Z",
     "shell.execute_reply.started": "2025-04-09T14:41:59.148597Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6869ef879c5644629d8df17643824270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e286008750495e94820ba837e756e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255b3d1fa3344677abf7fccc1efd7d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b5168c98494a44a0273a6afe01bc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016b98a21db64a9189bd85c1458f9bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training ---\n",
      "\n",
      "--- Epoch 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 1.8484\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c716982af125423080b40aa74e0dec61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6de43b9a1f24cd884774f96076514c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40305e649fdf4f8db069d6d21c5292e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89792fe838804fea864662c0a92c2124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c337062f3e6c400e8bde15a7361d79f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25db20cbe04b43f899089a773e537d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4918983d267a4ec5bfbaa40d65048a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c7b333afd643ddac7cc3fc54923fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a43eab3f3214faf97706f8ad67df727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Calculated:\n",
      "{'rouge1_precision': 0.6174682343799991, 'rouge1_recall': 0.5083284061357223, 'rouge1_fmeasure': 0.5379979686215518, 'rouge2_precision': 0.4355112749062329, 'rouge2_recall': 0.3497356043181718, 'rouge2_fmeasure': 0.3736501266790426, 'rougeL_precision': 0.5831083799487161, 'rougeL_recall': 0.4800769388053154, 'rougeL_fmeasure': 0.5081060896549834, 'bleu': 0.30609142781222914, 'bertscore_precision': 0.9225200414657593, 'bertscore_recall': 0.9103135466575623, 'bertscore_f1': 0.9161460399627686}\n",
      "Epoch 1 Validation Metrics:\n",
      "  rouge1_precision: 0.6175\n",
      "  rouge1_recall: 0.5083\n",
      "  rouge1_fmeasure: 0.5380\n",
      "  rouge2_precision: 0.4355\n",
      "  rouge2_recall: 0.3497\n",
      "  rouge2_fmeasure: 0.3737\n",
      "  rougeL_precision: 0.5831\n",
      "  rougeL_recall: 0.4801\n",
      "  rougeL_fmeasure: 0.5081\n",
      "  bleu: 0.3061\n",
      "  bertscore_precision: 0.9225\n",
      "  bertscore_recall: 0.9103\n",
      "  bertscore_f1: 0.9161\n",
      "Saving model state dict to: /kaggle/working/model_checkpoints/epoch_1/model.pkl\n",
      "Saving tokenizer to: /kaggle/working/model_checkpoints/epoch_1\n",
      "\n",
      "--- Epoch 2/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 1.3214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Calculated:\n",
      "{'rouge1_precision': 0.6247621071738719, 'rouge1_recall': 0.5227589435414789, 'rouge1_fmeasure': 0.5514960183593984, 'rouge2_precision': 0.45023959420598075, 'rouge2_recall': 0.371105417792889, 'rouge2_fmeasure': 0.3941704933481009, 'rougeL_precision': 0.5889351199687334, 'rougeL_recall': 0.49187262455479175, 'rougeL_fmeasure': 0.5198524342165057, 'bleu': 0.32369477132635693, 'bertscore_precision': 0.9249452352523804, 'bertscore_recall': 0.9132773280143738, 'bertscore_f1': 0.9188628196716309}\n",
      "Epoch 2 Validation Metrics:\n",
      "  rouge1_precision: 0.6248\n",
      "  rouge1_recall: 0.5228\n",
      "  rouge1_fmeasure: 0.5515\n",
      "  rouge2_precision: 0.4502\n",
      "  rouge2_recall: 0.3711\n",
      "  rouge2_fmeasure: 0.3942\n",
      "  rougeL_precision: 0.5889\n",
      "  rougeL_recall: 0.4919\n",
      "  rougeL_fmeasure: 0.5199\n",
      "  bleu: 0.3237\n",
      "  bertscore_precision: 0.9249\n",
      "  bertscore_recall: 0.9133\n",
      "  bertscore_f1: 0.9189\n",
      "Saving model state dict to: /kaggle/working/model_checkpoints/epoch_2/model.pkl\n",
      "Saving tokenizer to: /kaggle/working/model_checkpoints/epoch_2\n",
      "\n",
      "--- Epoch 3/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.9704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Calculated:\n",
      "{'rouge1_precision': 0.6255232447291271, 'rouge1_recall': 0.5295100404371137, 'rouge1_fmeasure': 0.5558628321666712, 'rouge2_precision': 0.4445375921930544, 'rouge2_recall': 0.37252222886396996, 'rouge2_fmeasure': 0.391755402705915, 'rougeL_precision': 0.591180281436584, 'rougeL_recall': 0.5021979835439279, 'rougeL_fmeasure': 0.526314888820969, 'bleu': 0.32561651074436193, 'bertscore_precision': 0.9252222776412964, 'bertscore_recall': 0.9159884452819824, 'bertscore_f1': 0.920348584651947}\n",
      "Epoch 3 Validation Metrics:\n",
      "  rouge1_precision: 0.6255\n",
      "  rouge1_recall: 0.5295\n",
      "  rouge1_fmeasure: 0.5559\n",
      "  rouge2_precision: 0.4445\n",
      "  rouge2_recall: 0.3725\n",
      "  rouge2_fmeasure: 0.3918\n",
      "  rougeL_precision: 0.5912\n",
      "  rougeL_recall: 0.5022\n",
      "  rougeL_fmeasure: 0.5263\n",
      "  bleu: 0.3256\n",
      "  bertscore_precision: 0.9252\n",
      "  bertscore_recall: 0.9160\n",
      "  bertscore_f1: 0.9203\n",
      "Saving model state dict to: /kaggle/working/model_checkpoints/epoch_3/model.pkl\n",
      "Saving tokenizer to: /kaggle/working/model_checkpoints/epoch_3\n",
      "\n",
      "--- Epoch 4/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.7336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Calculated:\n",
      "{'rouge1_precision': 0.6164396714396714, 'rouge1_recall': 0.519779039688791, 'rouge1_fmeasure': 0.5483260731642086, 'rouge2_precision': 0.4369193271714281, 'rouge2_recall': 0.36195212370101876, 'rouge2_fmeasure': 0.38439561866499, 'rougeL_precision': 0.58123284978327, 'rougeL_recall': 0.48949466979296924, 'rougeL_fmeasure': 0.5168683165777449, 'bleu': 0.31631220426130047, 'bertscore_precision': 0.9239041805267334, 'bertscore_recall': 0.9132238626480103, 'bertscore_f1': 0.918347954750061}\n",
      "Epoch 4 Validation Metrics:\n",
      "  rouge1_precision: 0.6164\n",
      "  rouge1_recall: 0.5198\n",
      "  rouge1_fmeasure: 0.5483\n",
      "  rouge2_precision: 0.4369\n",
      "  rouge2_recall: 0.3620\n",
      "  rouge2_fmeasure: 0.3844\n",
      "  rougeL_precision: 0.5812\n",
      "  rougeL_recall: 0.4895\n",
      "  rougeL_fmeasure: 0.5169\n",
      "  bleu: 0.3163\n",
      "  bertscore_precision: 0.9239\n",
      "  bertscore_recall: 0.9132\n",
      "  bertscore_f1: 0.9183\n",
      "Saving model state dict to: /kaggle/working/model_checkpoints/epoch_4/model.pkl\n",
      "Saving tokenizer to: /kaggle/working/model_checkpoints/epoch_4\n",
      "\n",
      "--- Epoch 5/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.5532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Calculated:\n",
      "{'rouge1_precision': 0.6374961275885646, 'rouge1_recall': 0.54055835284725, 'rouge1_fmeasure': 0.5688508778901757, 'rouge2_precision': 0.45362189817652004, 'rouge2_recall': 0.3798418158816994, 'rouge2_fmeasure': 0.4002821554616852, 'rougeL_precision': 0.6025915918815079, 'rougeL_recall': 0.5103353276342488, 'rougeL_fmeasure': 0.5373808264014763, 'bleu': 0.32016752289260914, 'bertscore_precision': 0.9261388182640076, 'bertscore_recall': 0.9163761734962463, 'bertscore_f1': 0.9210516214370728}\n",
      "Epoch 5 Validation Metrics:\n",
      "  rouge1_precision: 0.6375\n",
      "  rouge1_recall: 0.5406\n",
      "  rouge1_fmeasure: 0.5689\n",
      "  rouge2_precision: 0.4536\n",
      "  rouge2_recall: 0.3798\n",
      "  rouge2_fmeasure: 0.4003\n",
      "  rougeL_precision: 0.6026\n",
      "  rougeL_recall: 0.5103\n",
      "  rougeL_fmeasure: 0.5374\n",
      "  bleu: 0.3202\n",
      "  bertscore_precision: 0.9261\n",
      "  bertscore_recall: 0.9164\n",
      "  bertscore_f1: 0.9211\n",
      "Saving model state dict to: /kaggle/working/model_checkpoints/epoch_5/model.pkl\n",
      "Saving tokenizer to: /kaggle/working/model_checkpoints/epoch_5\n",
      "\n",
      "--- Epoch 6/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Calculated:\n",
      "{'rouge1_precision': 0.5921042664151908, 'rouge1_recall': 0.5229908144729495, 'rouge1_fmeasure': 0.5387949831499098, 'rouge2_precision': 0.40788839731696874, 'rouge2_recall': 0.35300754178177873, 'rouge2_fmeasure': 0.3670157453812976, 'rougeL_precision': 0.5533842889137007, 'rougeL_recall': 0.4868178291936702, 'rougeL_fmeasure': 0.5028045655502881, 'bleu': 0.3012895924754538, 'bertscore_precision': 0.920824408531189, 'bertscore_recall': 0.9144759774208069, 'bertscore_f1': 0.9174407124519348}\n",
      "Epoch 6 Validation Metrics:\n",
      "  rouge1_precision: 0.5921\n",
      "  rouge1_recall: 0.5230\n",
      "  rouge1_fmeasure: 0.5388\n",
      "  rouge2_precision: 0.4079\n",
      "  rouge2_recall: 0.3530\n",
      "  rouge2_fmeasure: 0.3670\n",
      "  rougeL_precision: 0.5534\n",
      "  rougeL_recall: 0.4868\n",
      "  rougeL_fmeasure: 0.5028\n",
      "  bleu: 0.3013\n",
      "  bertscore_precision: 0.9208\n",
      "  bertscore_recall: 0.9145\n",
      "  bertscore_f1: 0.9174\n",
      "Saving model state dict to: /kaggle/working/model_checkpoints/epoch_6/model.pkl\n",
      "Saving tokenizer to: /kaggle/working/model_checkpoints/epoch_6\n",
      "\n",
      "--- Epoch 7/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Calculated:\n",
      "{'rouge1_precision': 0.6153362076765438, 'rouge1_recall': 0.5538350750227122, 'rouge1_fmeasure': 0.5645293503147827, 'rouge2_precision': 0.45025453864529497, 'rouge2_recall': 0.3987495641842231, 'rouge2_fmeasure': 0.40831592715304216, 'rougeL_precision': 0.5846934340169634, 'rougeL_recall': 0.5239810145324132, 'rougeL_fmeasure': 0.5353093713173054, 'bleu': 0.3234946297198962, 'bertscore_precision': 0.9219918251037598, 'bertscore_recall': 0.9173619151115417, 'bertscore_f1': 0.9194568991661072}\n",
      "Epoch 7 Validation Metrics:\n",
      "  rouge1_precision: 0.6153\n",
      "  rouge1_recall: 0.5538\n",
      "  rouge1_fmeasure: 0.5645\n",
      "  rouge2_precision: 0.4503\n",
      "  rouge2_recall: 0.3987\n",
      "  rouge2_fmeasure: 0.4083\n",
      "  rougeL_precision: 0.5847\n",
      "  rougeL_recall: 0.5240\n",
      "  rougeL_fmeasure: 0.5353\n",
      "  bleu: 0.3235\n",
      "  bertscore_precision: 0.9220\n",
      "  bertscore_recall: 0.9174\n",
      "  bertscore_f1: 0.9195\n",
      "Saving model state dict to: /kaggle/working/model_checkpoints/epoch_7/model.pkl\n",
      "Saving tokenizer to: /kaggle/working/model_checkpoints/epoch_7\n",
      "\n",
      "--- Epoch 8/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.2316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Calculated:\n",
      "{'rouge1_precision': 0.622826909784893, 'rouge1_recall': 0.5291146423229871, 'rouge1_fmeasure': 0.5528557840389691, 'rouge2_precision': 0.43945861887878696, 'rouge2_recall': 0.3744228759993344, 'rouge2_fmeasure': 0.39004281226037735, 'rougeL_precision': 0.5867173703980425, 'rougeL_recall': 0.5022075399387016, 'rougeL_fmeasure': 0.5234083178206667, 'bleu': 0.3239130600526213, 'bertscore_precision': 0.9244793057441711, 'bertscore_recall': 0.9151553511619568, 'bertscore_f1': 0.9195706844329834}\n",
      "Epoch 8 Validation Metrics:\n",
      "  rouge1_precision: 0.6228\n",
      "  rouge1_recall: 0.5291\n",
      "  rouge1_fmeasure: 0.5529\n",
      "  rouge2_precision: 0.4395\n",
      "  rouge2_recall: 0.3744\n",
      "  rouge2_fmeasure: 0.3900\n",
      "  rougeL_precision: 0.5867\n",
      "  rougeL_recall: 0.5022\n",
      "  rougeL_fmeasure: 0.5234\n",
      "  bleu: 0.3239\n",
      "  bertscore_precision: 0.9245\n",
      "  bertscore_recall: 0.9152\n",
      "  bertscore_f1: 0.9196\n",
      "Saving model state dict to: /kaggle/working/model_checkpoints/epoch_8/model.pkl\n",
      "Saving tokenizer to: /kaggle/working/model_checkpoints/epoch_8\n",
      "\n",
      "--- Epoch 9/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Calculated:\n",
      "{'rouge1_precision': 0.6091538274983653, 'rouge1_recall': 0.5383019574211229, 'rouge1_fmeasure': 0.554771974107218, 'rouge2_precision': 0.43590832650076355, 'rouge2_recall': 0.37783479424473343, 'rouge2_fmeasure': 0.3919702041932421, 'rougeL_precision': 0.5727473730751041, 'rougeL_recall': 0.5033885242173212, 'rougeL_fmeasure': 0.5201948060554195, 'bleu': 0.31671566897442527, 'bertscore_precision': 0.9218881726264954, 'bertscore_recall': 0.914803147315979, 'bertscore_f1': 0.9181503057479858}\n",
      "Epoch 9 Validation Metrics:\n",
      "  rouge1_precision: 0.6092\n",
      "  rouge1_recall: 0.5383\n",
      "  rouge1_fmeasure: 0.5548\n",
      "  rouge2_precision: 0.4359\n",
      "  rouge2_recall: 0.3778\n",
      "  rouge2_fmeasure: 0.3920\n",
      "  rougeL_precision: 0.5727\n",
      "  rougeL_recall: 0.5034\n",
      "  rougeL_fmeasure: 0.5202\n",
      "  bleu: 0.3167\n",
      "  bertscore_precision: 0.9219\n",
      "  bertscore_recall: 0.9148\n",
      "  bertscore_f1: 0.9182\n",
      "Saving model state dict to: /kaggle/working/model_checkpoints/epoch_9/model.pkl\n",
      "Saving tokenizer to: /kaggle/working/model_checkpoints/epoch_9\n",
      "\n",
      "--- Epoch 10/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.1401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics Calculated:\n",
      "{'rouge1_precision': 0.6164762632325658, 'rouge1_recall': 0.5182278820641605, 'rouge1_fmeasure': 0.5462481215951914, 'rouge2_precision': 0.4351308294879724, 'rouge2_recall': 0.3594346647054233, 'rouge2_fmeasure': 0.3807501499557381, 'rougeL_precision': 0.5827098298526869, 'rougeL_recall': 0.4886256633460146, 'rougeL_fmeasure': 0.5162027500259964, 'bleu': 0.308688895738145, 'bertscore_precision': 0.9240379333496094, 'bertscore_recall': 0.9142255783081055, 'bertscore_f1': 0.9189184308052063}\n",
      "Epoch 10 Validation Metrics:\n",
      "  rouge1_precision: 0.6165\n",
      "  rouge1_recall: 0.5182\n",
      "  rouge1_fmeasure: 0.5462\n",
      "  rouge2_precision: 0.4351\n",
      "  rouge2_recall: 0.3594\n",
      "  rouge2_fmeasure: 0.3808\n",
      "  rougeL_precision: 0.5827\n",
      "  rougeL_recall: 0.4886\n",
      "  rougeL_fmeasure: 0.5162\n",
      "  bleu: 0.3087\n",
      "  bertscore_precision: 0.9240\n",
      "  bertscore_recall: 0.9142\n",
      "  bertscore_f1: 0.9189\n",
      "Saving model state dict to: /kaggle/working/model_checkpoints/epoch_10/model.pkl\n",
      "Saving tokenizer to: /kaggle/working/model_checkpoints/epoch_10\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_DATA_PATH = '/kaggle/input/muse-dataset/'\n",
    "TRAIN_TSV = os.path.join(BASE_DATA_PATH, 'train_df.tsv')\n",
    "VAL_TSV = os.path.join(BASE_DATA_PATH, 'val_df.tsv')\n",
    "TRAIN_OBJECTS_PKL = os.path.join(BASE_DATA_PATH, 'O_train.pkl')\n",
    "VAL_OBJECTS_PKL = os.path.join(BASE_DATA_PATH, 'O_val.pkl')\n",
    "TRAIN_DESCRIPTIONS_PKL = os.path.join(BASE_DATA_PATH, 'D_train.pkl')\n",
    "VAL_DESCRIPTIONS_PKL = os.path.join(BASE_DATA_PATH, 'D_val.pkl')\n",
    "IMAGE_DIR = os.path.join(BASE_DATA_PATH, 'images/')\n",
    "OUTPUT_DIR = '/kaggle/working/model_checkpoints/'\n",
    "\n",
    "BART_MODEL_NAME = \"facebook/bart-base\"\n",
    "VIT_MODEL_NAME = \"google/vit-base-patch16-224-in21k\"\n",
    "\n",
    "VIT_SEQ_LEN = 197\n",
    "TEXT_SEQ_LEN = 256\n",
    "EXP_MAX_LEN = 64\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "bart_tokenizer = BartTokenizer.from_pretrained(BART_MODEL_NAME)\n",
    "vit_processor = ViTImageProcessor.from_pretrained(VIT_MODEL_NAME)\n",
    "\n",
    "vit_feature_extractor = FeatureExtractorViT(VIT_MODEL_NAME).to(DEVICE)\n",
    "vit_feature_extractor.eval()\n",
    "\n",
    "try:\n",
    "    train_dataset = MuSEDataset(\n",
    "        tsv_path=TRAIN_TSV,\n",
    "        objects_pkl_path=TRAIN_OBJECTS_PKL,\n",
    "        descriptions_pkl_path=TRAIN_DESCRIPTIONS_PKL,\n",
    "        image_dir=IMAGE_DIR\n",
    "    )\n",
    "    val_dataset = MuSEDataset(\n",
    "        tsv_path=VAL_TSV,\n",
    "        objects_pkl_path=VAL_OBJECTS_PKL,\n",
    "        descriptions_pkl_path=VAL_DESCRIPTIONS_PKL,\n",
    "        image_dir=IMAGE_DIR\n",
    "    )\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading dataset files: {e}\")\n",
    "    print(\"Please ensure all dataset paths are correct.\")\n",
    "    exit()\n",
    "    \n",
    "data_collator = MuseDataCollator(\n",
    "    bart_tokenizer=bart_tokenizer,\n",
    "    vit_processor=vit_processor,\n",
    "    vit_model=vit_feature_extractor.vit_model, # Pass the actual ViT model part\n",
    "    text_max_len=TEXT_SEQ_LEN,\n",
    "    explanation_max_len=EXP_MAX_LEN,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    pin_memory=True if DEVICE == 'cuda' else False # Improve GPU transfer speed\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    pin_memory=True if DEVICE == 'cuda' else False\n",
    ")\n",
    "\n",
    "model = BART_SF(\n",
    "    bart_model_name=BART_MODEL_NAME,\n",
    "    bart_tokenizer=bart_tokenizer,\n",
    "    vit_feature_extractor=vit_feature_extractor,\n",
    "    vit_seq_len=VIT_SEQ_LEN,\n",
    "    text_seq_len=TEXT_SEQ_LEN\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "train_losses = []\n",
    "\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{NUM_EPOCHS} ---\")\n",
    "    avg_train_loss = train_epoch(model, train_dataloader, optimizer)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    val_metrics = evaluate_model(model, val_dataloader, bart_tokenizer, EXP_MAX_LEN)\n",
    "    if val_metrics:\n",
    "        print(f\"Epoch {epoch+1} Validation Metrics:\")\n",
    "        for metric, score in val_metrics.items():\n",
    "             if isinstance(score, dict):\n",
    "                 print(f\"  {metric}:\")\n",
    "                 for sub_metric, sub_score in score.items():\n",
    "                     print(f\"    {sub_metric}: {sub_score:.4f}\")\n",
    "             else:\n",
    "                 print(f\"  {metric}: {score:.4f}\")\n",
    "    else:\n",
    "        print(\"Validation evaluation failed.\")\n",
    "\n",
    "    epoch_checkpoint_dir = os.path.join(OUTPUT_DIR, f\"epoch_{epoch+1}\")\n",
    "    os.makedirs(epoch_checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    model_save_path = os.path.join(epoch_checkpoint_dir, \"model.pkl\")\n",
    "    print(f\"Saving model state dict to: {model_save_path}\")\n",
    "    torch.save(model, model_save_path)\n",
    "\n",
    "    print(f\"Saving tokenizer to: {epoch_checkpoint_dir}\")\n",
    "    model.bart_tokenizer.save_pretrained(epoch_checkpoint_dir)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, marker='o', linestyle='-', color='blue', label='Train Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T15:09:36.622378Z",
     "iopub.status.busy": "2025-04-09T15:09:36.622042Z",
     "iopub.status.idle": "2025-04-09T15:09:36.626685Z",
     "shell.execute_reply": "2025-04-09T15:09:36.625898Z",
     "shell.execute_reply.started": "2025-04-09T15:09:36.622345Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\amart\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\amart\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\amart\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics (ROUGE, BLEU(Sacre), METEOR, BERTScore) loaded via evaluate.\n",
      "Evaluation DataLoader contains 22 batches.\n",
      "Starting evaluation loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   5%|         | 1/22 [00:01<00:37,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample Outputs (Batch 1) ---\n",
      "\n",
      "[Sample 1]\n",
      "  Reference : the author hates the design of this convention center, it makes him dizzy.\n",
      "  Generated : the author hates the design of the convention center since it's cluttered.\n",
      "\n",
      "[Sample 2]\n",
      "  Reference : the author hates working late from home.\n",
      "  Generated : the author hates working late from home.\n",
      "\n",
      "[Sample 3]\n",
      "  Reference : your anxiety is not cured when someone says \"don't be anxious\".\n",
      "  Generated : the author is not a miracle worker since he said not to be anxious.\n",
      "\n",
      "[Sample 4]\n",
      "  Reference : the author is pissed to watch a full train leave station with half of them still on platform.\n",
      "  Generated : the author is sad for having to watch a full train leave station with half of us still\n",
      "\n",
      "[Sample 5]\n",
      "  Reference : the author doesn't find such notifications from linkedin to be useful.\n",
      "  Generated : the author didn't really linkedin, it's a self explanatory notification.\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating final metrics...\n",
      "Computing ROUGE...\n",
      "Computing BLEU (Sacre)...\n",
      "Computing METEOR...\n",
      "Computing BERTScore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics Calculated:\n",
      "\n",
      "Final Test Metrics:\n",
      "  rouge1: 0.5112\n",
      "  rouge2: 0.3298\n",
      "  rougeL: 0.4731\n",
      "  bleu: 0.2886\n",
      "  bleu-1: 0.6066\n",
      "  bleu-2: 0.4000\n",
      "  bleu-3: 0.3015\n",
      "  bleu-4: 0.2399\n",
      "  meteor: 0.4849\n",
      "  bertscore_precision: 0.9211\n",
      "  bertscore_recall: 0.9109\n",
      "  bertscore_f1: 0.9158\n"
     ]
    }
   ],
   "source": [
    "BASE_DATA_PATH = './'\n",
    "TEST_TSV = os.path.join(BASE_DATA_PATH, 'test_df.tsv')\n",
    "TEST_OBJECTS_PKL = os.path.join(BASE_DATA_PATH, 'O_test.pkl')\n",
    "TEST_DESCRIPTIONS_PKL = os.path.join(BASE_DATA_PATH, 'D_test.pkl')\n",
    "IMAGE_DIR = os.path.join(BASE_DATA_PATH, 'images/')\n",
    "\n",
    "CHECKPOINT_TO_LOAD_DIR = './epoch_8'\n",
    "\n",
    "BART_MODEL_NAME = \"facebook/bart-base\"\n",
    "VIT_MODEL_NAME = \"google/vit-base-patch16-224-in21k\"\n",
    "\n",
    "VIT_SEQ_LEN = 197\n",
    "TEXT_SEQ_LEN = 256\n",
    "EXP_MAX_LEN = 64\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "if not CHECKPOINT_TO_LOAD_DIR or not os.path.isdir(CHECKPOINT_TO_LOAD_DIR):\n",
    "    print(f\"Error: Specified checkpoint directory not found or not set: {CHECKPOINT_TO_LOAD_DIR}\")\n",
    "    exit()\n",
    "\n",
    "model_path = os.path.join(CHECKPOINT_TO_LOAD_DIR, \"model.pkl\")\n",
    "tokenizer_path = CHECKPOINT_TO_LOAD_DIR\n",
    "\n",
    "if not os.path.exists(model_path) or not os.path.exists(os.path.join(tokenizer_path, \"tokenizer_config.json\")):\n",
    "    print(f\"Error: Specified checkpoint directory {CHECKPOINT_TO_LOAD_DIR} is incomplete (missing model or tokenizer files).\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    bart_tokenizer = BartTokenizer.from_pretrained(tokenizer_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading tokenizer: {e}\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    model = torch.load(model_path, map_location=DEVICE, weights_only=False)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model state dict: {e}\")\n",
    "    exit()\n",
    "\n",
    "vit_processor = ViTImageProcessor.from_pretrained(VIT_MODEL_NAME)\n",
    "vit_feature_extractor_collator = FeatureExtractorViT(VIT_MODEL_NAME).to(DEVICE)\n",
    "vit_feature_extractor_collator.eval()\n",
    "\n",
    "try:\n",
    "    test_dataset = MuSEDataset(\n",
    "        tsv_path=TEST_TSV,\n",
    "        objects_pkl_path=TEST_OBJECTS_PKL,\n",
    "        descriptions_pkl_path=TEST_DESCRIPTIONS_PKL,\n",
    "        image_dir=IMAGE_DIR\n",
    "    )\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading test dataset files: {e}\")\n",
    "    exit()\n",
    "\n",
    "data_collator = MuseDataCollator(\n",
    "    bart_tokenizer=bart_tokenizer,\n",
    "    vit_processor=vit_processor,\n",
    "    vit_model=vit_feature_extractor_collator.vit_model,\n",
    "    text_max_len=TEXT_SEQ_LEN,\n",
    "    explanation_max_len=EXP_MAX_LEN\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if DEVICE == 'cuda' else False\n",
    ")\n",
    "\n",
    "test_metrics = evaluate_model(\n",
    "    model=model,\n",
    "    data_loader=test_dataloader,\n",
    "    tokenizer=bart_tokenizer,\n",
    "    max_gen_length=EXP_MAX_LEN,\n",
    "    num_samples_to_print = 5\n",
    ")\n",
    "\n",
    "if test_metrics:\n",
    "    print(\"\\nFinal Test Metrics:\")\n",
    "    for metric, score in test_metrics.items():\n",
    "        if isinstance(score, dict):\n",
    "            print(f\"  {metric}:\")\n",
    "            for sub_metric, sub_score in score.items():\n",
    "                print(f\"    {sub_metric}: {sub_score:.4f}\" if isinstance(sub_score, (int, float)) else f\"    {sub_metric}: {sub_score}\")\n",
    "        else:\n",
    "            print(f\"  {metric}: {score:.4f}\" if isinstance(score, (int, float)) else f\"  {metric}: {score}\")\n",
    "else:\n",
    "    print(\"Test evaluation failed or returned no metrics.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7093592,
     "sourceId": 11338941,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
